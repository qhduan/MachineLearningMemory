{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "### author qhduan@memect.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0-rc2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/JayParks/tf-seq2seq/blob/master/seq2seq_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = pickle.load(open('诗句.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "data = []\n",
    "sequence_length = []\n",
    "for s in sentences['X']:\n",
    "    q = s[:int(len(s)/2)]\n",
    "    a = s[int(len(s)/2):]\n",
    "    if len(q) > max_len:\n",
    "        max_len = len(q)\n",
    "    if len(q) > max_len:\n",
    "        max_len = len(a)\n",
    "    sequence_length.append(len(a))\n",
    "    data.append((q, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len is 7, size of data is 15158\n"
     ]
    }
   ],
   "source": [
    "print('max_len is {}, size of data is {}'.format(max_len, len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_tag = '<start>'\n",
    "end_tag = '<end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_2index = {}\n",
    "question_2word = {}\n",
    "\n",
    "answer_2index = {}\n",
    "answer_2word = {}\n",
    "\n",
    "for index, word in enumerate(sorted(list(set(''.join(x[0] for x in data))))):\n",
    "    question_2index[word] = index\n",
    "    question_2word[index] = word\n",
    "\n",
    "for index, word in enumerate([start_tag, end_tag] + sorted(list(set(''.join(x[1] for x in data))))):\n",
    "    answer_2index[word] = index\n",
    "    answer_2word[index] = word\n",
    "    \n",
    "question_size = len(question_2index)\n",
    "answer_size = len(answer_2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = answer_2index[start_tag]\n",
    "end_token = answer_2index[end_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> 0 <end> 1\n"
     ]
    }
   ],
   "source": [
    "print(start_tag, start_token, end_tag, end_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_size is 3798\n",
      "answer_size is 3879\n"
     ]
    }
   ],
   "source": [
    "print('question_size is {}'.format(question_size))\n",
    "print('answer_size is {}'.format(answer_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 7)\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=(batch_size, max_len),\n",
    "    name='encoder_inputs'\n",
    ")\n",
    "print(encoder_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs_length = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=(batch_size,),\n",
    "    name='encoder_inputs_length'\n",
    ")\n",
    "print(encoder_inputs_length.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 7)\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=(batch_size, max_len),\n",
    "    name='decoder_inputs'\n",
    ")\n",
    "print(decoder_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs_length = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=(batch_size,),\n",
    "    name='decoder_inputs_length'\n",
    ")\n",
    "print(decoder_inputs_length.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_start_token = tf.ones(\n",
    "    shape=(batch_size, 1),\n",
    "    dtype=tf.int32\n",
    ") * start_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_end_token = tf.ones(\n",
    "    shape=(batch_size, 1),\n",
    "    dtype=tf.int32\n",
    ") * end_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8)\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs_train = tf.concat([\n",
    "    decoder_start_token, decoder_inputs\n",
    "], axis=1)\n",
    "print(decoder_inputs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8)\n"
     ]
    }
   ],
   "source": [
    "decoder_targets_train = tf.concat([\n",
    "    decoder_inputs, decoder_end_token\n",
    "], axis=1)\n",
    "print(decoder_targets_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8)\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs_weights = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=(batch_size, max_len + 1),\n",
    "    name='decoder_inputs_weights'\n",
    ")\n",
    "print(decoder_inputs_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "sqrt3 = math.sqrt(3)\n",
    "initializer = tf.random_uniform_initializer(\n",
    "    -sqrt3,\n",
    "    sqrt3,\n",
    "    dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_embeddings = tf.get_variable(\n",
    "    name='encoder_embeddings',\n",
    "    shape=(question_size, embedding_size),\n",
    "    initializer=initializer,\n",
    "    dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "    params=encoder_embeddings,\n",
    "    ids=encoder_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = tf.contrib.rnn.LSTMCell(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs, encoder_last_state = tf.nn.dynamic_rnn(\n",
    "    cell=encoder_cell,\n",
    "    inputs=encoder_inputs_embedded,\n",
    "    sequence_length=encoder_inputs_length,\n",
    "    dtype=tf.float32,\n",
    "    time_major=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_embeddings = tf.get_variable(\n",
    "    name='ecoder_embeddings',\n",
    "    shape=(answer_size, embedding_size),\n",
    "    initializer=initializer,\n",
    "    dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer = Dense(\n",
    "    512,\n",
    "    dtype=tf.float32,\n",
    "    name='input_projection'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs_embedded = input_layer(tf.nn.embedding_lookup(\n",
    "    params=decoder_embeddings,\n",
    "    ids=decoder_inputs_train\n",
    "))\n",
    "print(decoder_inputs_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_inputs_length_train = decoder_inputs_length + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "    inputs=decoder_inputs_embedded,\n",
    "    sequence_length=decoder_inputs_length_train,\n",
    "    time_major=False,\n",
    "    name='training_helper'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.LSTMCell(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_layer = Dense(\n",
    "    answer_size,\n",
    "    name='output_projection'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial_state = [state for state in encoder_last_state]\n",
    "initial_state = encoder_last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial_state[-1] = decoder_cell.zero_state(\n",
    "#     batch_size=batch_size,\n",
    "#     dtype=tf.float32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_state = tuple(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    cell=decoder_cell,\n",
    "    helper=training_helper,\n",
    "    initial_state=initial_state,\n",
    "    output_layer=output_layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicDecoderOutput(rnn_output=TensorShape([Dimension(3879)]), sample_id=TensorShape([]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_decoder.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_decoder_length = tf.reduce_max(\n",
    "    decoder_inputs_length_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    decoder_outputs_train,\n",
    "    decoder_last_state_train,\n",
    "    decoder_outputs_length_decode\n",
    ") = tf.contrib.seq2seq.dynamic_decode(\n",
    "    decoder=training_decoder,\n",
    "    output_time_major=False,\n",
    "    impute_finished=True,\n",
    "    maximum_iterations=max_decoder_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_outputs_length_decode.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"decoder/transpose:0\", shape=(32, ?, 3879), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_outputs_train.rnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, ?, 3879)\n"
     ]
    }
   ],
   "source": [
    "decoder_logits_train = tf.identity(\n",
    "    decoder_outputs_train.rnn_output\n",
    ")\n",
    "print(decoder_logits_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, ?)\n"
     ]
    }
   ],
   "source": [
    "decoder_pred_train = tf.argmax(\n",
    "    decoder_logits_train, axis=-1,\n",
    "    name='decoder_pred_train'\n",
    ")\n",
    "print(decoder_pred_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, ?)\n"
     ]
    }
   ],
   "source": [
    "masks = tf.sequence_mask(\n",
    "    lengths=decoder_inputs_length_train,\n",
    "    maxlen=max_decoder_length,\n",
    "    dtype=tf.float32,\n",
    "    name='masks'\n",
    ")\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, ?, 3879)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_logits_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_targets_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, ?)\n"
     ]
    }
   ],
   "source": [
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=decoder_logits_train,\n",
    "    targets=decoder_targets_train,\n",
    "    weights=decoder_inputs_weights,\n",
    "    average_across_timesteps=True,\n",
    "    average_across_batch=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainable_params = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(\n",
    "    learning_rate=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradients = tf.gradients(loss, trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip_gradients, _ = tf.clip_by_global_norm(\n",
    "    gradients, 1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updates = opt.apply_gradients(\n",
    "    zip(gradients, trainable_params),\n",
    "    global_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_and_input_proj(inputs):\n",
    "    return input_layer(\n",
    "        tf.nn.embedding_lookup(decoder_embeddings, inputs)\n",
    "    )\n",
    "\n",
    "start_tokens = tf.ones([batch_size,], tf.int32) * start_token\n",
    "\n",
    "decoding_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "    start_tokens=start_tokens,\n",
    "    end_token=end_token,\n",
    "    embedding=embed_and_input_proj\n",
    ")\n",
    "\n",
    "inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    cell=decoder_cell,\n",
    "    helper=decoding_helper,\n",
    "    initial_state=initial_state,\n",
    "    output_layer=output_layer\n",
    ")\n",
    "\n",
    "(\n",
    "    decoder_outputs_decode,\n",
    "    decoder_last_state_decode,\n",
    "    decoder_outputs_length_decode\n",
    ") = tf.contrib.seq2seq.dynamic_decode(\n",
    "    decoder=inference_decoder,\n",
    "    output_time_major=False,\n",
    "    # impute_finished=True,\t# error occurs\n",
    "    maximum_iterations=max_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_pred_decode = tf.expand_dims(\n",
    "    decoder_outputs_decode.sample_id,\n",
    "    -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_flow(\n",
    "    data,\n",
    "    question_2index, answer_2index, max_len, batch_size=4\n",
    "):\n",
    "    X = []\n",
    "    Y = []\n",
    "    XL = []\n",
    "    YL = []\n",
    "    W = []\n",
    "    for q, a in data:\n",
    "        if len(X) == batch_size:\n",
    "            yield (\n",
    "                np.array(X),\n",
    "                np.array(XL),\n",
    "                np.array(Y),\n",
    "                np.array(YL),\n",
    "                np.array(W)\n",
    "            )\n",
    "            X = []\n",
    "            XL = []\n",
    "            Y = []\n",
    "            YL = []\n",
    "            W = []\n",
    "        x = [1] * max_len\n",
    "        for ind, qq in enumerate(list(q)):\n",
    "            x[ind] = question_2index[qq]\n",
    "        y = [1] * max_len\n",
    "        w = [0] * (max_len + 1)\n",
    "        for ind, aa in enumerate(list(a)):\n",
    "            y[ind] = answer_2index[aa]\n",
    "            w[ind] = 1.0\n",
    "        w[ind + 1] = 1.0\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        XL.append(len(q))\n",
    "        YL.append(max_len)\n",
    "        W.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7) (4,) (4, 7) (4,) (4, 8)\n",
      "----------\n",
      "[[ 678 3494   49   21  157    1    1]\n",
      " [2056 3580  728 2830 2751    1    1]\n",
      " [3794 2867 2190  544 3588    1    1]\n",
      " [1670  665  153 1067 2745    1    1]]\n",
      "----------\n",
      "[5 5 5 5]\n",
      "----------\n",
      "[[ 483 2985 2392 3097 3538    1    1]\n",
      " [1198  582  669 2795 1645    1    1]\n",
      " [ 243 1190 3332 2056 2347    1    1]\n",
      " [ 509 1101 3182 3733   86    1    1]]\n",
      "----------\n",
      "[7 7 7 7]\n",
      "----------\n",
      "[[ 1.  1.  1.  1.  1.  1.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "for x, xl, y, yl, w in batch_flow(\n",
    "    data, question_2index, answer_2index, max_len, 4\n",
    "):\n",
    "    print(x.shape, xl.shape, y.shape, yl.shape, w.shape)\n",
    "    print('-' * 10)\n",
    "    print(x)\n",
    "    print('-' * 10)\n",
    "    print(xl)\n",
    "    print('-' * 10)\n",
    "    print(y)\n",
    "    print('-' * 10)\n",
    "    print(yl)\n",
    "    print('-' * 10)\n",
    "    print(w)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss = tf.contrib.seq2seq.sequence_loss(\n",
    "#     logits=decoder_logits_train,\n",
    "#     targets=decoder_targets_train,\n",
    "#     weights=masks,\n",
    "#     average_across_timesteps=True,\n",
    "#     average_across_batch=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(outputs):\n",
    "    print([\n",
    "        [answer_2word[item[0]] for item in batch]\n",
    "        for batch in outputs\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:16,  6.17it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:14,  6.82it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:00<00:13,  7.37it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:00<00:12,  7.76it/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:00<00:11,  8.06it/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:00<00:11,  8.40it/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:00<00:11,  8.32it/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:00<00:10,  8.57it/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:01<00:10,  8.68it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:01<00:10,  8.71it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:01<00:10,  8.55it/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:01<00:10,  8.57it/s]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:01<00:09,  8.76it/s]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:01<00:09,  8.89it/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:01<00:09,  8.96it/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:01<00:09,  9.07it/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:01<00:09,  9.11it/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:02<00:08,  9.12it/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:02<00:08,  9.16it/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:02<00:08,  9.05it/s]\u001b[A\n",
      " 21%|██        | 21/100 [00:02<00:09,  8.75it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:02<00:08,  8.93it/s]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:02<00:08,  9.09it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:02<00:08,  9.17it/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:02<00:08,  9.09it/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:02<00:08,  9.05it/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:03<00:08,  9.09it/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:03<00:07,  9.11it/s]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:03<00:07,  9.15it/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:03<00:07,  8.86it/s]\u001b[A\n",
      " 31%|███       | 31/100 [00:03<00:08,  8.60it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:03<00:07,  8.56it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:03<00:07,  8.81it/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:03<00:07,  8.81it/s]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:03<00:07,  8.66it/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:04<00:07,  8.60it/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:04<00:07,  8.51it/s]\u001b[A\n",
      " 38%|███▊      | 38/100 [00:04<00:07,  8.31it/s]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:04<00:07,  8.37it/s]\u001b[A\n",
      " 40%|████      | 40/100 [00:04<00:07,  8.54it/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:04<00:06,  8.57it/s]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:04<00:06,  8.42it/s]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:04<00:06,  8.60it/s]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:05<00:06,  8.76it/s]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:05<00:06,  8.84it/s]\u001b[A\n",
      " 46%|████▌     | 46/100 [00:05<00:06,  8.88it/s]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:05<00:06,  8.79it/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:05<00:05,  8.69it/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:05<00:05,  8.55it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:05<00:05,  8.64it/s]\u001b[A\n",
      " 51%|█████     | 51/100 [00:05<00:05,  8.71it/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:05<00:05,  8.68it/s]\u001b[A\n",
      " 53%|█████▎    | 53/100 [00:06<00:05,  8.55it/s]\u001b[A\n",
      " 54%|█████▍    | 54/100 [00:06<00:05,  8.69it/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:06<00:05,  8.81it/s]\u001b[A\n",
      " 56%|█████▌    | 56/100 [00:06<00:04,  8.93it/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:06<00:04,  8.99it/s]\u001b[A\n",
      " 58%|█████▊    | 58/100 [00:06<00:04,  9.08it/s]\u001b[A\n",
      " 59%|█████▉    | 59/100 [00:06<00:04,  9.05it/s]\u001b[A\n",
      " 60%|██████    | 60/100 [00:06<00:04,  8.81it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:06<00:04,  8.59it/s]\u001b[A\n",
      " 62%|██████▏   | 62/100 [00:07<00:04,  8.57it/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [00:07<00:04,  8.78it/s]\u001b[A\n",
      " 64%|██████▍   | 64/100 [00:07<00:04,  8.93it/s]\u001b[A\n",
      " 65%|██████▌   | 65/100 [00:07<00:03,  8.99it/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:07<00:03,  9.05it/s]\u001b[A\n",
      " 67%|██████▋   | 67/100 [00:07<00:03,  9.14it/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [00:07<00:03,  9.18it/s]\u001b[A\n",
      " 69%|██████▉   | 69/100 [00:07<00:03,  9.23it/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:07<00:03,  9.10it/s]\u001b[A\n",
      " 71%|███████   | 71/100 [00:08<00:03,  9.02it/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [00:08<00:03,  8.99it/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [00:08<00:02,  9.01it/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:08<00:02,  9.04it/s]\u001b[A\n",
      " 75%|███████▌  | 75/100 [00:08<00:02,  9.08it/s]\u001b[A\n",
      " 76%|███████▌  | 76/100 [00:08<00:02,  9.14it/s]\u001b[A\n",
      " 77%|███████▋  | 77/100 [00:08<00:02,  9.12it/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:08<00:02,  9.14it/s]\u001b[A\n",
      " 79%|███████▉  | 79/100 [00:08<00:02,  9.21it/s]\u001b[A\n",
      " 80%|████████  | 80/100 [00:09<00:02,  9.10it/s]\u001b[A\n",
      " 81%|████████  | 81/100 [00:09<00:02,  9.07it/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:09<00:02,  8.91it/s]\u001b[A\n",
      " 83%|████████▎ | 83/100 [00:09<00:01,  8.77it/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [00:09<00:01,  8.75it/s]\u001b[A\n",
      " 99%|█████████▉| 99/100 [00:11<00:00,  9.58it/s]model saved at model/-100\n",
      "[['不', '不', '<end>', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '<end>', '<end>'], ['不', '不', '<end>', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '<end>', '<end>'], ['不', '不', '<end>', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '<end>', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '<end>', '<end>'], ['不', '不', '<end>', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '<end>', '<end>'], ['不', '不', '<end>', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>'], ['不', '不', '相', '<end>']]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        print('epoch {}'.format(\n",
    "            epoch\n",
    "        ))\n",
    "        costs = []\n",
    "        \n",
    "        for x, xl, y, yl, w in tqdm(batch_flow(\n",
    "            data, question_2index, answer_2index, max_len, batch_size\n",
    "        ), total=steps, file=sys.stdout):\n",
    "            \n",
    "#             input_feed = {\n",
    "#                 encoder_inputs: x,\n",
    "#                 encoder_inputs_length: xl,\n",
    "#                 decoder_inputs: y,\n",
    "#                 decoder_inputs_length: yl\n",
    "#             }\n",
    "            \n",
    "#             t = sess.run([\n",
    "#                 decoder_logits_train,\n",
    "#                 decoder_targets_train,\n",
    "#                 masks\n",
    "#             ], input_feed)\n",
    "#             break\n",
    "#             print(x.shape, xl.shape, y.shape, yl.shape)\n",
    "            \n",
    "            input_feed = {\n",
    "                encoder_inputs: x,\n",
    "                encoder_inputs_length: xl,\n",
    "                decoder_inputs: y,\n",
    "                decoder_inputs_length: yl,\n",
    "                decoder_inputs_weights: w\n",
    "            }\n",
    "            output_feed = [updates, loss]\n",
    "            _, c = sess.run(output_feed, input_feed)\n",
    "            costs.append(c)\n",
    "            if len(costs) >= steps:\n",
    "                break\n",
    "#         break\n",
    "        print('')\n",
    "        print('cost: {:.4f}'.format(\n",
    "            np.mean(costs)\n",
    "        ))\n",
    "    saver = tf.train.Saver(None)\n",
    "    save_path = saver.save(\n",
    "        sess,\n",
    "        save_path='model/',\n",
    "        global_step=global_step\n",
    "    )\n",
    "    print('model saved at %s' % save_path)\n",
    "    \n",
    "    for x, xl, y, yl, w in batch_flow(\n",
    "            data, question_2index, answer_2index, max_len, batch_size\n",
    "    ):\n",
    "        input_feed = {\n",
    "            encoder_inputs: x,\n",
    "            encoder_inputs_length: xl\n",
    "        }\n",
    "        outputs = sess.run([decoder_pred_decode], input_feed)\n",
    "        print(get_result(outputs[0]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
