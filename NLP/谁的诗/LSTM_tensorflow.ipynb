{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "### author qhduan@memect.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本量：12126，测试集样本量：3032\n"
     ]
    }
   ],
   "source": [
    "from data import X_train, X_test, y_train, y_test\n",
    "from data import fit_vectorizer, fit_onehot\n",
    "from data import batch_flow, test_batch_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单个训练样本最大长度：14\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "PAD = ' ' # 句子不到max_len长度时的占位符\n",
    "max_len = max(len(x) for x in X_train)\n",
    "print('单个训练样本最大长度：{}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = fit_vectorizer(X_train, embedding_size, max_len, PAD)\n",
    "onehot = fit_onehot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps 14\n",
      "input_size 128\n",
      "target_size 2\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "num_units = 128\n",
    "batch_size = 256\n",
    "time_steps = max_len\n",
    "input_size = embedding_size\n",
    "target_size = len(onehot.feature_indices_)\n",
    "print('time_steps', time_steps)\n",
    "print('input_size', input_size)\n",
    "print('target_size', target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 14, 128) (256, 2)\n"
     ]
    }
   ],
   "source": [
    "test_batch_flow(X_train, y_train, batch_size, vectorizer, onehot, max_len, PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [time_steps, batch_size, input_size], name='X')\n",
    "y = tf.placeholder(tf.float32, [batch_size, target_size], name='X')\n",
    "weight = tf.Variable(tf.random_normal([time_steps * num_units, target_size]), name='weight')\n",
    "bias = tf.Variable(tf.zeros([target_size]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"dynamic_scope\", reuse=None):\n",
    "    cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "    outputs, states = tf.nn.dynamic_rnn(\n",
    "        cell,\n",
    "        inputs=X,\n",
    "        time_major=True, dtype=tf.float32\n",
    "    )\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "    outputs = tf.reshape(outputs, [batch_size, -1])\n",
    "    pred = tf.nn.softmax(tf.add(tf.matmul(outputs, weight), bias))\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    cost = tf.reduce_mean(\n",
    "        -tf.reduce_sum(y * tf.log(pred),\n",
    "        reduction_indices=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-343d609387cf>:2 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# 初始化所有变量\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# disable GPU，关闭GPU支持\n",
    "config = tf.ConfigProto(\n",
    "    device_count = {'GPU': 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cost: 0.7441 acc: 0.6445\n",
      "epoch 1 cost: 0.6644 acc: 0.7148\n",
      "epoch 2 cost: 0.6417 acc: 0.7383\n",
      "epoch 3 cost: 0.6272 acc: 0.7734\n",
      "epoch 4 cost: 0.6161 acc: 0.7852\n",
      "epoch 5 cost: 0.6068 acc: 0.8008\n",
      "epoch 6 cost: 0.5985 acc: 0.8047\n",
      "epoch 7 cost: 0.5908 acc: 0.8164\n",
      "epoch 8 cost: 0.5835 acc: 0.8242\n",
      "epoch 9 cost: 0.5762 acc: 0.8203\n",
      "epoch 10 cost: 0.5684 acc: 0.8242\n",
      "train cost: 0.5548 acc: 0.8242\n",
      "test cost: 0.7549 acc: 0.5703\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch + 1):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        for X_sample, y_sample in batch_flow(X_train, y_train, batch_size, vectorizer, onehot, max_len, PAD):\n",
    "            feeds = {X: X_sample.reshape([time_steps, batch_size, input_size]), y: y_sample}\n",
    "            sess.run(train_step, feeds)\n",
    "            c, acc = sess.run([cost, accuracy], feeds)\n",
    "            costs.append(c)\n",
    "            accs.append(acc)\n",
    "        print('epoch {} cost: {:.4f} acc: {:.4f}'.format(\n",
    "            epoch, np.mean(costs), np.mean(acc)\n",
    "        ))\n",
    "    # train\n",
    "    costs = []\n",
    "    accs = []\n",
    "    for X_sample, y_sample in batch_flow(X_train, y_train, batch_size, vectorizer, onehot, max_len, PAD):\n",
    "        feeds = {X: X_sample.reshape([time_steps, batch_size, input_size]), y: y_sample}\n",
    "        c, acc = sess.run([cost, accuracy], feeds)\n",
    "        costs.append(c)\n",
    "        accs.append(acc)\n",
    "    print('train cost: {:.4f} acc: {:.4f}'.format(np.mean(costs), np.mean(acc)))\n",
    "    # test\n",
    "    costs = []\n",
    "    accs = []\n",
    "    for X_sample, y_sample in batch_flow(X_test, y_test, batch_size, vectorizer, onehot, max_len, PAD):\n",
    "        feeds = {X: X_sample.reshape([time_steps, batch_size, input_size]), y: y_sample}\n",
    "        c, acc = sess.run([cost, accuracy], feeds)\n",
    "        costs.append(c)\n",
    "        accs.append(acc)\n",
    "    print('test cost: {:.4f} acc: {:.4f}'.format(np.mean(costs), np.mean(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
